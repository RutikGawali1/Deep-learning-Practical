{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["DeepLearning\n","Practical 3:-Neural Network with a Single Hidden Layer"],"metadata":{"id":"WbyZhWQFYmVY"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"eMzEqZppRNUW","executionInfo":{"status":"ok","timestamp":1679031597854,"user_tz":-330,"elapsed":642,"user":{"displayName":"Rutik Gawali","userId":"00471114392500016437"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data = np.genfromtxt('/content/data_banknote_authentication.txt', delimiter = ',')\n","X = data[:,:4]\n","y = data[:, 4]"],"metadata":{"id":"fhyGFwyETtU7","executionInfo":{"status":"ok","timestamp":1679031821001,"user_tz":-330,"elapsed":668,"user":{"displayName":"Rutik Gawali","userId":"00471114392500016437"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["plt.scatter(X[:, 0], X[:, 1], alpha=0.2,\n"," c=y, cmap='viridis')\n","plt.xlabel('variance of wavelet')\n","plt.ylabel('skewness of wavelet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"ynEgUAFHUq4i","outputId":"4cd7bc26-6ad2-48b3-d978-fd730b5b6bb4","executionInfo":{"status":"error","timestamp":1679031534048,"user_tz":-330,"elapsed":408,"user":{"displayName":"Rutik Gawali","userId":"00471114392500016437"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-4e79313a1844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plt.scatter(X[:, 0], X[:, 1], alpha=0.2,\n\u001b[0m\u001b[1;32m      2\u001b[0m  c=y, cmap='viridis')\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variance of wavelet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skewness of wavelet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train = X_train.T\n","y_train = y_train.reshape(1, y_train.shape[0])\n","X_test = X_test.T\n","y_test = y_test.reshape(1, y_test.shape[0])\n","print ('Train X Shape: ', X_train.shape)\n","print ('Train Y Shape: ', y_train.shape)\n","print ('I have m = %d training examples!' % (X_train.shape[1]))\n","\n","print ('\\nTest X Shape: ', X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovyRdtKCU-dy","outputId":"0a1adfe1-4aa6-44ec-fde1-8c758c4791ce","executionInfo":{"status":"ok","timestamp":1678786653479,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rutik Gawali","userId":"00471114392500016437"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train X Shape:  (4, 1097)\n","Train Y Shape:  (1, 1097)\n","I have m = 1097 training examples!\n","\n","Test X Shape:  (4, 275)\n"]}]},{"cell_type":"code","source":["def define_structure(X, Y):\n","    input_unit = X.shape[0] # size of input layer\n","    hidden_unit = 1 #hidden layer of size 1\n","    output_unit = Y.shape[0] # size of output layer\n","    return (input_unit, hidden_unit, output_unit)\n","(input_unit, hidden_unit, output_unit) = define_structure(X_train, y_train)\n","print(\"The size of the input layer is:  = \" + str(input_unit))\n","print(\"The size of the hidden layer is:  = \" + str(hidden_unit))\n","print(\"The size of the output layer is:  = \" + str(output_unit))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naTUOVsTVhTq","outputId":"bba57602-92ae-4263-b350-97131942800c","executionInfo":{"status":"ok","timestamp":1678786655364,"user_tz":-330,"elapsed":860,"user":{"displayName":"Rutik Gawali","userId":"00471114392500016437"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the input layer is:  = 4\n","The size of the hidden layer is:  = 1\n","The size of the output layer is:  = 1\n"]}]},{"cell_type":"code","source":["def parameters_initialization(input_unit, hidden_unit, output_unit):\n","    np.random.seed(2) \n","    W1 = np.random.randn(hidden_unit, input_unit)*0.01\n","    b1 = np.zeros((hidden_unit, 1))\n","    W2 = np.random.randn(output_unit, hidden_unit)*0.01\n","    b2 = np.zeros((output_unit, 1))\n","    parameters = {\"W1\": W1,\n","                  \"b1\": b1,\n","                  \"W2\": W2,\n","                  \"b2\": b2}\n","    \n","    return parameters"],"metadata":{"id":"qpvg3cLZVm3B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sigmoid(z):\n","    return 1/(1+np.exp(-z))\n","def forward_propagation(X, parameters):\n","    W1 = parameters['W1']\n","    b1 = parameters['b1']\n","    W2 = parameters['W2']\n","    b2 = parameters['b2']\n","    \n","    Z1 = np.dot(W1, X) + b1\n","    A1 = np.tanh(Z1)\n","    Z2 = np.dot(W2, A1) + b2\n","    A2 = sigmoid(Z2)\n","    cache = {\"Z1\": Z1,\"A1\": A1,\"Z2\": Z2,\"A2\": A2}\n","    \n","    return A2, cache"],"metadata":{"id":"DSVpPK2rVqJy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cross_entropy_cost(A2, Y, parameters):\n","    # number of training example\n","    m = Y.shape[1] \n","    # Compute the cross-entropy cost\n","    logprobs = np.multiply(np.log(A2), Y) + np.multiply((1-Y), np.log(1 - A2))\n","    cost = - np.sum(logprobs) / m\n","    cost = float(np.squeeze(cost))\n","                                    \n","    return cost"],"metadata":{"id":"rZ09aIq7VtfB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def backward_propagation(parameters, cache, X, Y):\n","    #number of training example\n","    m = X.shape[1]\n","    \n","    W1 = parameters['W1']\n","    W2 = parameters['W2']\n","    A1 = cache['A1']\n","    A2 = cache['A2']\n","   \n","    dZ2 = A2-Y\n","    dW2 = (1/m) * np.dot(dZ2, A1.T)\n","    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n","    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n","    dW1 = (1/m) * np.dot(dZ1, X.T) \n","    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n","    \n","    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2,\"db2\": db2}\n","    \n","    return grads"],"metadata":{"id":"844C-0gsVvyx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gradient_descent(parameters, grads, learning_rate = 0.01):\n","    W1 = parameters['W1']\n","    b1 = parameters['b1']\n","    W2 = parameters['W2']\n","    b2 = parameters['b2']\n","   \n","    dW1 = grads['dW1']\n","    db1 = grads['db1']\n","    dW2 = grads['dW2']\n","    db2 = grads['db2']\n","    W1 = W1 - learning_rate * dW1\n","    b1 = b1 - learning_rate * db1\n","    W2 = W2 - learning_rate * dW2\n","    b2 = b2 - learning_rate * db2\n","    \n","    parameters = {\"W1\": W1, \"b1\": b1,\"W2\": W2,\"b2\": b2}\n","    \n","    return parameters"],"metadata":{"id":"s7raJTgzVyd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def neural_network_model(X, Y, hidden_unit, num_iterations = 1000):\n","    np.random.seed(3)\n","    input_unit = define_structure(X, Y)[0]\n","    output_unit = define_structure(X, Y)[2]\n","    \n","    parameters = parameters_initialization(input_unit, hidden_unit, output_unit)\n","   \n","    W1 = parameters['W1']\n","    b1 = parameters['b1']\n","    W2 = parameters['W2']\n","    b2 = parameters['b2']\n","    \n","    for i in range(0, num_iterations):\n","        A2, cache = forward_propagation(X, parameters)\n","        cost = cross_entropy_cost(A2, Y, parameters)\n","        grads = backward_propagation(parameters, cache, X, Y)\n","        parameters = gradient_descent(parameters, grads)\n","        if i % 5 == 0:\n","            print (\"Cost after iteration %i: %f\" %(i, cost))\n","    return parameters\n","parameters = neural_network_model(X_train, y_train, 4, num_iterations=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsh48x9_V0gi","outputId":"beaba960-a39a-4e08-d840-bae9c7c161a1","executionInfo":{"status":"ok","timestamp":1678786658756,"user_tz":-330,"elapsed":1112,"user":{"displayName":"Rutik Gawali","userId":"00471114392500016437"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cost after iteration 0: 0.692975\n","Cost after iteration 5: 0.692665\n","Cost after iteration 10: 0.692351\n","Cost after iteration 15: 0.692028\n","Cost after iteration 20: 0.691692\n","Cost after iteration 25: 0.691338\n","Cost after iteration 30: 0.690962\n","Cost after iteration 35: 0.690557\n","Cost after iteration 40: 0.690117\n","Cost after iteration 45: 0.689636\n","Cost after iteration 50: 0.689107\n","Cost after iteration 55: 0.688521\n","Cost after iteration 60: 0.687873\n","Cost after iteration 65: 0.687152\n","Cost after iteration 70: 0.686352\n","Cost after iteration 75: 0.685463\n","Cost after iteration 80: 0.684477\n","Cost after iteration 85: 0.683388\n","Cost after iteration 90: 0.682187\n","Cost after iteration 95: 0.680866\n","Cost after iteration 100: 0.679420\n","Cost after iteration 105: 0.677843\n","Cost after iteration 110: 0.676127\n","Cost after iteration 115: 0.674268\n","Cost after iteration 120: 0.672259\n","Cost after iteration 125: 0.670096\n","Cost after iteration 130: 0.667773\n","Cost after iteration 135: 0.665286\n","Cost after iteration 140: 0.662629\n","Cost after iteration 145: 0.659797\n","Cost after iteration 150: 0.656787\n","Cost after iteration 155: 0.653594\n","Cost after iteration 160: 0.650215\n","Cost after iteration 165: 0.646648\n","Cost after iteration 170: 0.642889\n","Cost after iteration 175: 0.638938\n","Cost after iteration 180: 0.634794\n","Cost after iteration 185: 0.630457\n","Cost after iteration 190: 0.625929\n","Cost after iteration 195: 0.621210\n","Cost after iteration 200: 0.616305\n","Cost after iteration 205: 0.611217\n","Cost after iteration 210: 0.605950\n","Cost after iteration 215: 0.600512\n","Cost after iteration 220: 0.594907\n","Cost after iteration 225: 0.589145\n","Cost after iteration 230: 0.583233\n","Cost after iteration 235: 0.577180\n","Cost after iteration 240: 0.570995\n","Cost after iteration 245: 0.564687\n","Cost after iteration 250: 0.558268\n","Cost after iteration 255: 0.551746\n","Cost after iteration 260: 0.545132\n","Cost after iteration 265: 0.538436\n","Cost after iteration 270: 0.531668\n","Cost after iteration 275: 0.524840\n","Cost after iteration 280: 0.517962\n","Cost after iteration 285: 0.511044\n","Cost after iteration 290: 0.504098\n","Cost after iteration 295: 0.497134\n","Cost after iteration 300: 0.490163\n","Cost after iteration 305: 0.483197\n","Cost after iteration 310: 0.476244\n","Cost after iteration 315: 0.469317\n","Cost after iteration 320: 0.462425\n","Cost after iteration 325: 0.455576\n","Cost after iteration 330: 0.448781\n","Cost after iteration 335: 0.442047\n","Cost after iteration 340: 0.435381\n","Cost after iteration 345: 0.428791\n","Cost after iteration 350: 0.422283\n","Cost after iteration 355: 0.415862\n","Cost after iteration 360: 0.409532\n","Cost after iteration 365: 0.403299\n","Cost after iteration 370: 0.397165\n","Cost after iteration 375: 0.391133\n","Cost after iteration 380: 0.385205\n","Cost after iteration 385: 0.379383\n","Cost after iteration 390: 0.373667\n","Cost after iteration 395: 0.368060\n","Cost after iteration 400: 0.362561\n","Cost after iteration 405: 0.357170\n","Cost after iteration 410: 0.351887\n","Cost after iteration 415: 0.346712\n","Cost after iteration 420: 0.341643\n","Cost after iteration 425: 0.336679\n","Cost after iteration 430: 0.331820\n","Cost after iteration 435: 0.327064\n","Cost after iteration 440: 0.322409\n","Cost after iteration 445: 0.317854\n","Cost after iteration 450: 0.313397\n","Cost after iteration 455: 0.309037\n","Cost after iteration 460: 0.304771\n","Cost after iteration 465: 0.300598\n","Cost after iteration 470: 0.296516\n","Cost after iteration 475: 0.292523\n","Cost after iteration 480: 0.288616\n","Cost after iteration 485: 0.284795\n","Cost after iteration 490: 0.281056\n","Cost after iteration 495: 0.277399\n","Cost after iteration 500: 0.273820\n","Cost after iteration 505: 0.270319\n","Cost after iteration 510: 0.266893\n","Cost after iteration 515: 0.263540\n","Cost after iteration 520: 0.260259\n","Cost after iteration 525: 0.257048\n","Cost after iteration 530: 0.253905\n","Cost after iteration 535: 0.250828\n","Cost after iteration 540: 0.247815\n","Cost after iteration 545: 0.244866\n","Cost after iteration 550: 0.241977\n","Cost after iteration 555: 0.239148\n","Cost after iteration 560: 0.236378\n","Cost after iteration 565: 0.233663\n","Cost after iteration 570: 0.231004\n","Cost after iteration 575: 0.228398\n","Cost after iteration 580: 0.225845\n","Cost after iteration 585: 0.223343\n","Cost after iteration 590: 0.220889\n","Cost after iteration 595: 0.218485\n","Cost after iteration 600: 0.216127\n","Cost after iteration 605: 0.213815\n","Cost after iteration 610: 0.211547\n","Cost after iteration 615: 0.209323\n","Cost after iteration 620: 0.207141\n","Cost after iteration 625: 0.205000\n","Cost after iteration 630: 0.202900\n","Cost after iteration 635: 0.200838\n","Cost after iteration 640: 0.198815\n","Cost after iteration 645: 0.196829\n","Cost after iteration 650: 0.194879\n","Cost after iteration 655: 0.192964\n","Cost after iteration 660: 0.191084\n","Cost after iteration 665: 0.189237\n","Cost after iteration 670: 0.187423\n","Cost after iteration 675: 0.185641\n","Cost after iteration 680: 0.183890\n","Cost after iteration 685: 0.182170\n","Cost after iteration 690: 0.180479\n","Cost after iteration 695: 0.178817\n","Cost after iteration 700: 0.177183\n","Cost after iteration 705: 0.175577\n","Cost after iteration 710: 0.173998\n","Cost after iteration 715: 0.172445\n","Cost after iteration 720: 0.170918\n","Cost after iteration 725: 0.169415\n","Cost after iteration 730: 0.167938\n","Cost after iteration 735: 0.166484\n","Cost after iteration 740: 0.165054\n","Cost after iteration 745: 0.163646\n","Cost after iteration 750: 0.162261\n","Cost after iteration 755: 0.160898\n","Cost after iteration 760: 0.159556\n","Cost after iteration 765: 0.158234\n","Cost after iteration 770: 0.156934\n","Cost after iteration 775: 0.155653\n","Cost after iteration 780: 0.154392\n","Cost after iteration 785: 0.153150\n","Cost after iteration 790: 0.151926\n","Cost after iteration 795: 0.150721\n","Cost after iteration 800: 0.149534\n","Cost after iteration 805: 0.148364\n","Cost after iteration 810: 0.147212\n","Cost after iteration 815: 0.146076\n","Cost after iteration 820: 0.144957\n","Cost after iteration 825: 0.143854\n","Cost after iteration 830: 0.142767\n","Cost after iteration 835: 0.141695\n","Cost after iteration 840: 0.140639\n","Cost after iteration 845: 0.139597\n","Cost after iteration 850: 0.138570\n","Cost after iteration 855: 0.137557\n","Cost after iteration 860: 0.136558\n","Cost after iteration 865: 0.135573\n","Cost after iteration 870: 0.134602\n","Cost after iteration 875: 0.133643\n","Cost after iteration 880: 0.132698\n","Cost after iteration 885: 0.131765\n","Cost after iteration 890: 0.130845\n","Cost after iteration 895: 0.129937\n","Cost after iteration 900: 0.129041\n","Cost after iteration 905: 0.128156\n","Cost after iteration 910: 0.127284\n","Cost after iteration 915: 0.126422\n","Cost after iteration 920: 0.125572\n","Cost after iteration 925: 0.124733\n","Cost after iteration 930: 0.123904\n","Cost after iteration 935: 0.123086\n","Cost after iteration 940: 0.122279\n","Cost after iteration 945: 0.121481\n","Cost after iteration 950: 0.120694\n","Cost after iteration 955: 0.119916\n","Cost after iteration 960: 0.119148\n","Cost after iteration 965: 0.118390\n","Cost after iteration 970: 0.117641\n","Cost after iteration 975: 0.116901\n","Cost after iteration 980: 0.116170\n","Cost after iteration 985: 0.115447\n","Cost after iteration 990: 0.114734\n","Cost after iteration 995: 0.114029\n"]}]},{"cell_type":"code","source":["def prediction(parameters, X):\n","    A2, cache = forward_propagation(X, parameters)\n","    predictions = np.round(A2)\n","    \n","    return predictions"],"metadata":{"id":"8Gs9KeJvV3JR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = prediction(parameters, X_train)\n","print ('Accuracy Train: %d' % float((np.dot(y_train, predictions.T) + np.dot(1 - y_train, 1 - predictions.T))/float(y_train.size)*100) + '%')\n","predictions = prediction(parameters, X_test)\n","print ('Accuracy Test: %d' % float((np.dot(y_test, predictions.T) + np.dot(1 - y_test, 1 - predictions.T))/float(y_test.size)*100) + '%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iu25NCsnV6Ux","outputId":"ddba95d1-c3f8-46e7-9ad8-9566454a4c0b","executionInfo":{"status":"ok","timestamp":1678786658757,"user_tz":-330,"elapsed":18,"user":{"displayName":"Rutik Gawali","userId":"00471114392500016437"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Train: 97%\n","Accuracy Test: 96%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xCTn9yrZe3mj"},"execution_count":null,"outputs":[]}]}